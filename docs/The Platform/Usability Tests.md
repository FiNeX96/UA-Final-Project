# Usability Tests and results

To enhance our platform's user experience, we conducted usability testing, gathering direct feedback from users to ensure the platform is both efficient and enjoyable. 

We involved two diverse group of participants, students and teachers (not done, yet), to reflect our user base's varied needs and conducted the testing in tasks. 

The feedback from these sessions was crucial for understanding user's needs and to refine our platform. Our aim is to create a more intuitive and satisfying experience for all users, demonstrating our commitment to continuous improvement based on user feedback.

## On the prototype (Figma)

On March 21st, we took a Usability test in person with 19 participants, 3 females and 16 males, from Human-Computer Interaction course, all young adults. We presented 5 differents tasks, which were:

1. Log in and indicate how many master's dissertations are on the website and how many are available. 

2. Analyze the dissertation "UI Design principles and their effects in network traffic" and indicate the name of the supervisor, co-supervisor and the courses for which it is intended.

3. Show interest in the "AI-based River Discharge Forecasting" dissertation and indicate which message appeared to confirm your choice.  

4. Remove interest in the dissertation "Porcupine: Visualization and Analysis of Multimodal Interaction" and indicate the number of dissertations that are present in the profile and the student's course code. 

5. Check the new notification received and sign the agreement already signed by the professor. Indicate the location of the assigned dissertation and the confirmation message. 

### Results

We registered a 96.8% task completion ratio. Below, it's possible to see all tasks and if the participant completed it or not.

![Use Case diagram](../../static/img/completedTasks.png)

We also registered a 78.9% task success rate, i.e. if the participant reached the right answers.

![Use Case diagram](../../static/img/successTasks.png)

After finishing the tasks, we presented a post-task questionnaire. The following figure that it's shown has this property:

On even numbered questions the best score is 5 and on odd numbered questions the best score is 1.

![Use Case diagram](../../static/img/ASQ.png)

With this data, it's also possible to calculate the SUS (System Usability Scale) score, which is 91, and because it's greater than 68, this means that the system is considered to be usable.

### Suggested Improvements and notes

  

  